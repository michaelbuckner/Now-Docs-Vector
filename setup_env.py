#!/usr/bin/env python3
"""Setup environment configuration for ServiceNow Documentation Vectorizer"""

import click
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.panel import Panel

console = Console()


def create_env_file():
    """Interactive setup for .env file"""
    console.print(Panel.fit(
        "[bold cyan]ServiceNow Documentation Vectorizer - Environment Setup[/bold cyan]",
        border_style="cyan"
    ))
    
    console.print("\nThis wizard will help you create a .env configuration file.\n")
    
    # Check if .env already exists
    env_path = Path(".env")
    if env_path.exists():
        overwrite = Confirm.ask("[yellow].env file already exists. Overwrite?[/yellow]", default=False)
        if not overwrite:
            console.print("[yellow]Setup cancelled.[/yellow]")
            return
    
    # Embedding configuration
    console.print("\n[bold cyan]1. Embedding Model Configuration[/bold cyan]")
    console.print("Choose your embedding model type:")
    console.print("  [green]local[/green] - Free, no API key required (recommended for getting started)")
    console.print("  [yellow]openai[/yellow] - Better quality, requires API key")
    
    embedding_type = Prompt.ask(
        "Embedding model type",
        choices=["local", "openai"],
        default="local"
    )
    
    openai_key = ""
    if embedding_type == "openai":
        openai_key = Prompt.ask("OpenAI API Key", password=True)
        embedding_model = Prompt.ask(
            "OpenAI embedding model",
            choices=["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"],
            default="text-embedding-3-small"
        )
    else:
        embedding_model = Prompt.ask(
            "Local embedding model",
            choices=["all-MiniLM-L6-v2", "all-mpnet-base-v2"],
            default="all-MiniLM-L6-v2"
        )
    
    # Database configuration
    console.print("\n[bold cyan]2. Database Configuration[/bold cyan]")
    
    db_path = Prompt.ask(
        "Database directory",
        default="./chroma_db"
    )
    
    collection_name = Prompt.ask(
        "Collection name",
        default="servicenow_docs"
    )
    
    # Chunking configuration
    console.print("\n[bold cyan]3. Document Chunking Configuration[/bold cyan]")
    console.print("Larger chunks preserve more context but may be less precise.")
    console.print("Smaller chunks are more precise but may lose context.")
    
    chunk_size = Prompt.ask(
        "Chunk size (characters)",
        default="1000"
    )
    
    chunk_overlap = Prompt.ask(
        "Chunk overlap (characters)",
        default="200"
    )
    
    # Search configuration
    console.print("\n[bold cyan]4. Search Configuration[/bold cyan]")
    
    max_results = Prompt.ask(
        "Default max results",
        default="10"
    )
    
    threshold = Prompt.ask(
        "Similarity threshold (0.0-1.0)",
        default="0.7"
    )
    
    # MCP Server configuration
    console.print("\n[bold cyan]5. MCP Server Configuration[/bold cyan]")
    
    mcp_port = Prompt.ask(
        "MCP server port",
        default="3333"
    )
    
    mcp_host = Prompt.ask(
        "MCP server host",
        default="localhost"
    )
    
    # Create .env content
    env_content = f"""# ServiceNow Documentation Vectorizer Configuration
# Generated by setup_env.py

# OpenAI API Configuration (optional - using local embeddings by default)
"""
    
    if openai_key:
        env_content += f"OPENAI_API_KEY={openai_key}\n"
    else:
        env_content += "# OPENAI_API_KEY=your_openai_api_key_here\n"
    
    env_content += f"""
# Vector Database Configuration
CHROMA_PERSIST_DIRECTORY={db_path}
COLLECTION_NAME={collection_name}

# Embedding Model Configuration
EMBEDDING_MODEL_TYPE={embedding_type}
EMBEDDING_MODEL_NAME={embedding_model}

# Chunking Configuration
CHUNK_SIZE={chunk_size}
CHUNK_OVERLAP={chunk_overlap}

# MCP Server Configuration
MCP_SERVER_PORT={mcp_port}
MCP_SERVER_HOST={mcp_host}

# Search Configuration
MAX_RESULTS={max_results}
SIMILARITY_THRESHOLD={threshold}
"""
    
    # Write .env file
    with open(".env", "w") as f:
        f.write(env_content)
    
    console.print("\n[bold green]✅ .env file created successfully![/bold green]")
    
    # Show next steps
    console.print("\n[bold cyan]Next Steps:[/bold cyan]")
    console.print("1. Run [yellow]python test_setup.py[/yellow] to verify your setup")
    console.print("2. Run [yellow]python index_docs.py[/yellow] to index your documentation")
    console.print("3. Run [yellow]python query_docs.py --interactive[/yellow] to test searches")
    console.print("4. Run [yellow]python mcp_server.py[/yellow] to start the MCP server")
    
    # Offer to run test
    if Confirm.ask("\n[cyan]Would you like to run the setup test now?[/cyan]", default=True):
        import subprocess
        subprocess.run([sys.executable, "test_setup.py"])


@click.command()
@click.option('--non-interactive', is_flag=True, help='Use default values without prompting')
def main(non_interactive):
    """Setup environment configuration"""
    
    if non_interactive:
        # Create default .env file
        default_env = """# ServiceNow Documentation Vectorizer Configuration
# Generated by setup_env.py (non-interactive mode)

# OpenAI API Configuration (optional - using local embeddings by default)
# OPENAI_API_KEY=your_openai_api_key_here

# Vector Database Configuration
CHROMA_PERSIST_DIRECTORY=./chroma_db
COLLECTION_NAME=servicenow_docs

# Embedding Model Configuration
EMBEDDING_MODEL_TYPE=local
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# MCP Server Configuration
MCP_SERVER_PORT=3333
MCP_SERVER_HOST=localhost

# Search Configuration
MAX_RESULTS=10
SIMILARITY_THRESHOLD=0.7
"""
        with open(".env", "w") as f:
            f.write(default_env)
        
        console.print("[green]✅ Created .env file with default configuration[/green]")
    else:
        create_env_file()


if __name__ == "__main__":
    import sys
    main()
